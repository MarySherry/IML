{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our problem is an image recognition problem, to identify digits from a given 28 x 28 image. We have a subset of images for training and the rest for testing our model. So first, download the train and test files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to increase the speed of calculations look only at 2s and 7s\n",
    "train_picks = np.logical_or(y_train==2,y_train==7)\n",
    "test_picks = np.logical_or(y_test==2,y_test==7)\n",
    "\n",
    "x_train = x_train[train_picks]\n",
    "x_test = x_test[test_picks]\n",
    "y_train = np.array(y_train[train_picks]==7,dtype=int)\n",
    "y_test = np.array(y_test[test_picks]==7,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN converg faster on [0..1] data than on [0..255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors \n",
    "y_train = to_categorical(y_train, num_classes = 2)\n",
    "y_test = to_categorical(y_test, num_classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build simple CNN models to classify the MNIST dataset and uses sklearn's GridSearchCV to find the best hyperparameter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 5s 601us/step - loss: 0.0549 - acc: 0.9821\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 432us/step - loss: 0.0298 - acc: 0.9914\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 431us/step - loss: 0.0198 - acc: 0.9941\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 431us/step - loss: 0.0142 - acc: 0.9962\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 468us/step - loss: 0.0109 - acc: 0.9977\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 440us/step - loss: 0.0093 - acc: 0.9979\n",
      "4075/4075 [==============================] - 0s 118us/step\n",
      "8148/8148 [==============================] - 1s 99us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 4s 488us/step - loss: 0.0531 - acc: 0.9844\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 449us/step - loss: 0.0233 - acc: 0.9934\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 439us/step - loss: 0.0154 - acc: 0.9945\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 446us/step - loss: 0.0110 - acc: 0.9962\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 460us/step - loss: 0.0077 - acc: 0.9980\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 430us/step - loss: 0.0052 - acc: 0.9988\n",
      "4074/4074 [==============================] - 0s 123us/step\n",
      "8149/8149 [==============================] - 1s 109us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 4s 473us/step - loss: 0.0547 - acc: 0.9807\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 442us/step - loss: 0.0270 - acc: 0.9928\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 436us/step - loss: 0.0200 - acc: 0.9956\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 449us/step - loss: 0.0151 - acc: 0.9961\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 464us/step - loss: 0.0118 - acc: 0.9973\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 432us/step - loss: 0.0088 - acc: 0.9977\n",
      "4074/4074 [==============================] - 1s 126us/step\n",
      "8149/8149 [==============================] - 1s 104us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 2s 278us/step - loss: 0.0571 - acc: 0.9820\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 2s 236us/step - loss: 0.0278 - acc: 0.9909\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 2s 231us/step - loss: 0.0188 - acc: 0.9944\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 2s 233us/step - loss: 0.0138 - acc: 0.9964\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 2s 233us/step - loss: 0.0107 - acc: 0.9975\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 2s 231us/step - loss: 0.0079 - acc: 0.9983\n",
      "4075/4075 [==============================] - 0s 91us/step\n",
      "8148/8148 [==============================] - 1s 62us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 280us/step - loss: 0.0543 - acc: 0.9831\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 2s 242us/step - loss: 0.0228 - acc: 0.9915\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 2s 242us/step - loss: 0.0146 - acc: 0.9953\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 2s 242us/step - loss: 0.0112 - acc: 0.9972\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 2s 268us/step - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 2s 236us/step - loss: 0.0054 - acc: 0.9985\n",
      "4074/4074 [==============================] - 0s 94us/step\n",
      "8149/8149 [==============================] - 1s 66us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 300us/step - loss: 0.0587 - acc: 0.9811\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 2s 239us/step - loss: 0.0272 - acc: 0.9918\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0210 - acc: 0.9941\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 2s 234us/step - loss: 0.0165 - acc: 0.9957\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 2s 245us/step - loss: 0.0130 - acc: 0.9967\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 2s 239us/step - loss: 0.0110 - acc: 0.9973\n",
      "4074/4074 [==============================] - 0s 100us/step\n",
      "8149/8149 [==============================] - 1s 69us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 2s 207us/step - loss: 0.0667 - acc: 0.9779\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 1s 146us/step - loss: 0.0297 - acc: 0.9909\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 1s 132us/step - loss: 0.0218 - acc: 0.9939\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 1s 133us/step - loss: 0.0155 - acc: 0.9958\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 1s 138us/step - loss: 0.0118 - acc: 0.9972\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 1s 139us/step - loss: 0.0084 - acc: 0.9983\n",
      "4075/4075 [==============================] - 0s 84us/step\n",
      "8148/8148 [==============================] - 0s 43us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 200us/step - loss: 0.0610 - acc: 0.9807\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0244 - acc: 0.9919\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 132us/step - loss: 0.0145 - acc: 0.9953\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 133us/step - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 132us/step - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 131us/step - loss: 0.0049 - acc: 0.9984\n",
      "4074/4074 [==============================] - 0s 84us/step\n",
      "8149/8149 [==============================] - 0s 43us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 202us/step - loss: 0.0705 - acc: 0.9759\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 133us/step - loss: 0.0312 - acc: 0.9906\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 131us/step - loss: 0.0225 - acc: 0.9941\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 132us/step - loss: 0.0160 - acc: 0.9956\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 132us/step - loss: 0.0117 - acc: 0.9968\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 131us/step - loss: 0.0086 - acc: 0.9973\n",
      "4074/4074 [==============================] - 0s 88us/step\n",
      "8149/8149 [==============================] - 0s 42us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 1s 170us/step - loss: 0.0714 - acc: 0.9768\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0303 - acc: 0.9907\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 1s 99us/step - loss: 0.0217 - acc: 0.9939\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 1s 103us/step - loss: 0.0153 - acc: 0.9962\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 1s 98us/step - loss: 0.0078 - acc: 0.9977\n",
      "4075/4075 [==============================] - 0s 85us/step\n",
      "8148/8148 [==============================] - 0s 33us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 222us/step - loss: 0.0677 - acc: 0.9773\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0261 - acc: 0.9904\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 102us/step - loss: 0.0167 - acc: 0.9945\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 102us/step - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 97us/step - loss: 0.0055 - acc: 0.9984\n",
      "4074/4074 [==============================] - 0s 89us/step\n",
      "8149/8149 [==============================] - 0s 35us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 1s 180us/step - loss: 0.0709 - acc: 0.9809\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.0309 - acc: 0.9913\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 106us/step - loss: 0.0221 - acc: 0.9937\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 106us/step - loss: 0.0166 - acc: 0.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0121 - acc: 0.9969\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 97us/step - loss: 0.0101 - acc: 0.9979\n",
      "4074/4074 [==============================] - 0s 98us/step\n",
      "8149/8149 [==============================] - 0s 34us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 1s 167us/step - loss: 0.0854 - acc: 0.9702\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 1s 77us/step - loss: 0.0354 - acc: 0.9888\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 1s 79us/step - loss: 0.0251 - acc: 0.9930\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 1s 77us/step - loss: 0.0175 - acc: 0.9953\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 1s 77us/step - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 1s 77us/step - loss: 0.0103 - acc: 0.9977\n",
      "4075/4075 [==============================] - 0s 94us/step\n",
      "8148/8148 [==============================] - 0s 29us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 1s 173us/step - loss: 0.0787 - acc: 0.9726\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 81us/step - loss: 0.0298 - acc: 0.9896\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 76us/step - loss: 0.0187 - acc: 0.9939\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 79us/step - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 77us/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 83us/step - loss: 0.0066 - acc: 0.9985\n",
      "4074/4074 [==============================] - 0s 102us/step\n",
      "8149/8149 [==============================] - 0s 30us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 190us/step - loss: 0.0823 - acc: 0.9730\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 79us/step - loss: 0.0349 - acc: 0.9901\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 78us/step - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 80us/step - loss: 0.0186 - acc: 0.9947\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 81us/step - loss: 0.0139 - acc: 0.9968\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 91us/step - loss: 0.0119 - acc: 0.9961\n",
      "4074/4074 [==============================] - 0s 109us/step\n",
      "8149/8149 [==============================] - 0s 29us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 1s 174us/step - loss: 0.0838 - acc: 0.9694\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 1s 67us/step - loss: 0.0357 - acc: 0.9894\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 1s 74us/step - loss: 0.0263 - acc: 0.9921\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 1s 66us/step - loss: 0.0199 - acc: 0.9942\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 1s 66us/step - loss: 0.0154 - acc: 0.9961\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 1s 70us/step - loss: 0.0106 - acc: 0.9968\n",
      "4075/4075 [==============================] - 0s 112us/step\n",
      "8148/8148 [==============================] - 0s 25us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 196us/step - loss: 0.0810 - acc: 0.9737\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 66us/step - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 69us/step - loss: 0.0225 - acc: 0.9925\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 71us/step - loss: 0.0162 - acc: 0.9942\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 68us/step - loss: 0.0116 - acc: 0.9971\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 67us/step - loss: 0.0094 - acc: 0.9974\n",
      "4074/4074 [==============================] - 0s 121us/step\n",
      "8149/8149 [==============================] - 0s 27us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 2s 198us/step - loss: 0.0855 - acc: 0.9730\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 1s 68us/step - loss: 0.0355 - acc: 0.9893\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 1s 67us/step - loss: 0.0263 - acc: 0.9925\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 1s 68us/step - loss: 0.0195 - acc: 0.9947\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 1s 67us/step - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 1s 70us/step - loss: 0.0120 - acc: 0.9963\n",
      "4074/4074 [==============================] - 1s 134us/step\n",
      "8149/8149 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 7s 543us/step - loss: 0.0476 - acc: 0.9840\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 6s 478us/step - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 6s 465us/step - loss: 0.0164 - acc: 0.9961\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 6s 466us/step - loss: 0.0137 - acc: 0.9971\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 6s 470us/step - loss: 0.0107 - acc: 0.9973\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 6s 489us/step - loss: 0.0091 - acc: 0.9980\n",
      "Best: 0.992800 using {'batch_size': 10, 'epochs': 6}\n",
      "0.992800 (0.001335) with: {'batch_size': 10, 'epochs': 6}\n",
      "0.992228 (0.001478) with: {'batch_size': 20, 'epochs': 6}\n",
      "0.992637 (0.001591) with: {'batch_size': 40, 'epochs': 6}\n",
      "0.992555 (0.000989) with: {'batch_size': 60, 'epochs': 6}\n",
      "0.992637 (0.001219) with: {'batch_size': 80, 'epochs': 6}\n",
      "0.991491 (0.001104) with: {'batch_size': 100, 'epochs': 6}\n",
      "Best: 0.992800 using {'batch_size': 10, 'epochs': 6}\n",
      "2060/2060 [==============================] - 1s 355us/step\n",
      "Test Accuracy 0.9927184451552271\n"
     ]
    }
   ],
   "source": [
    "##### BATCH SIZE #####\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [6],\n",
    "              'batch_size': [10, 20, 40, 60, 80, 100]}\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 6s 694us/step - loss: 0.0551 - acc: 0.9823\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 5s 556us/step - loss: 0.0299 - acc: 0.9914\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 5s 635us/step - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 5s 618us/step - loss: 0.0143 - acc: 0.9964\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 5s 591us/step - loss: 0.0111 - acc: 0.9975\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 518us/step - loss: 0.0093 - acc: 0.9979\n",
      "4075/4075 [==============================] - 1s 265us/step\n",
      "8148/8148 [==============================] - 1s 142us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 5s 628us/step - loss: 0.0532 - acc: 0.9843\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 475us/step - loss: 0.0233 - acc: 0.9931\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 524us/step - loss: 0.0156 - acc: 0.9945\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 5s 626us/step - loss: 0.0114 - acc: 0.9961\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 5s 573us/step - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 490us/step - loss: 0.0055 - acc: 0.9985\n",
      "4074/4074 [==============================] - 1s 262us/step\n",
      "8149/8149 [==============================] - 1s 148us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 5s 620us/step - loss: 0.0547 - acc: 0.9805\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 489us/step - loss: 0.0272 - acc: 0.9929\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 521us/step - loss: 0.0202 - acc: 0.9956\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 484us/step - loss: 0.0151 - acc: 0.9964\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 505us/step - loss: 0.0118 - acc: 0.9973\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 484us/step - loss: 0.0089 - acc: 0.9979\n",
      "4074/4074 [==============================] - 1s 270us/step\n",
      "8149/8149 [==============================] - 1s 146us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 5s 640us/step - loss: 0.0539 - acc: 0.9831\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 497us/step - loss: 0.0282 - acc: 0.9914\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 497us/step - loss: 0.0206 - acc: 0.9939\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 484us/step - loss: 0.0157 - acc: 0.9966\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 495us/step - loss: 0.0128 - acc: 0.9972\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 497us/step - loss: 0.0092 - acc: 0.9978\n",
      "4075/4075 [==============================] - 1s 283us/step\n",
      "8148/8148 [==============================] - 1s 151us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 5s 666us/step - loss: 0.0505 - acc: 0.9838\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 508us/step - loss: 0.0228 - acc: 0.9919\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 505us/step - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 532us/step - loss: 0.0125 - acc: 0.9967\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 496us/step - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 508us/step - loss: 0.0067 - acc: 0.9982\n",
      "4074/4074 [==============================] - 1s 284us/step\n",
      "8149/8149 [==============================] - 1s 154us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 5s 659us/step - loss: 0.0557 - acc: 0.9823\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 486us/step - loss: 0.0270 - acc: 0.9924\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 497us/step - loss: 0.0215 - acc: 0.9945\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 505us/step - loss: 0.0175 - acc: 0.9958\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 503us/step - loss: 0.0138 - acc: 0.9969\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 502us/step - loss: 0.0126 - acc: 0.9973\n",
      "4074/4074 [==============================] - 1s 289us/step\n",
      "8149/8149 [==============================] - 1s 148us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 8s 630us/step - loss: 0.0480 - acc: 0.9832\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 6s 491us/step - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 6s 500us/step - loss: 0.0167 - acc: 0.9957\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 6s 503us/step - loss: 0.0131 - acc: 0.9965\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 6s 531us/step - loss: 0.0107 - acc: 0.9975\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 6s 508us/step - loss: 0.0096 - acc: 0.9980\n",
      "Best: 0.993210 using {'batch_size': 10, 'epochs': 6, 'optimizer': 'SGD'}\n",
      "0.993210 (0.001633) with: {'batch_size': 10, 'epochs': 6, 'optimizer': 'SGD'}\n",
      "0.992964 (0.001728) with: {'batch_size': 10, 'epochs': 6, 'optimizer': 'Adam'}\n",
      "Best: 0.993210 using {'batch_size': 10, 'epochs': 6, 'optimizer': 'SGD'}\n",
      "2060/2060 [==============================] - 1s 475us/step\n",
      "Test Accuracy 0.9917475711373449\n"
     ]
    }
   ],
   "source": [
    "##### OPTIMIZATION ALGORITHM #####\n",
    "\n",
    "def create_model(optimizer):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [6],\n",
    "              'batch_size': [10],\n",
    "              'optimizer': ['SGD', 'Adam']\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 5s 596us/step - loss: 0.1111 - acc: 0.9672\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 311us/step - loss: 0.0479 - acc: 0.9850\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 3s 364us/step - loss: 0.0393 - acc: 0.9881\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 3s 327us/step - loss: 0.0339 - acc: 0.9905\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 3s 363us/step - loss: 0.0299 - acc: 0.9913\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 3s 340us/step - loss: 0.0270 - acc: 0.9921\n",
      "4075/4075 [==============================] - 1s 316us/step\n",
      "8148/8148 [==============================] - 1s 157us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 4s 523us/step - loss: 0.1087 - acc: 0.9694\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 380us/step - loss: 0.0460 - acc: 0.9848\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 342us/step - loss: 0.0369 - acc: 0.9881\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 340us/step - loss: 0.0317 - acc: 0.9902\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 348us/step - loss: 0.0275 - acc: 0.9912\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 336us/step - loss: 0.0245 - acc: 0.9923\n",
      "4074/4074 [==============================] - 1s 314us/step\n",
      "8149/8149 [==============================] - 1s 166us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 4s 532us/step - loss: 0.1004 - acc: 0.9710\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 346us/step - loss: 0.0501 - acc: 0.9845\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 360us/step - loss: 0.0418 - acc: 0.9874\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 388us/step - loss: 0.0366 - acc: 0.9886\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 386us/step - loss: 0.0333 - acc: 0.9894\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 471us/step - loss: 0.0286 - acc: 0.9910\n",
      "4074/4074 [==============================] - 1s 333us/step\n",
      "8149/8149 [==============================] - 2s 224us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 5s 555us/step - loss: 0.1052 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 350us/step - loss: 0.0502 - acc: 0.9834\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 5s 610us/step - loss: 0.0407 - acc: 0.9869\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 3s 351us/step - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 3s 410us/step - loss: 0.0315 - acc: 0.9908\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 3s 367us/step - loss: 0.0281 - acc: 0.9918\n",
      "4075/4075 [==============================] - 1s 346us/step\n",
      "8148/8148 [==============================] - 2s 191us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 6s 737us/step - loss: 0.1074 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 345us/step - loss: 0.0443 - acc: 0.9860\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 352us/step - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 374us/step - loss: 0.0304 - acc: 0.9898\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 369us/step - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 373us/step - loss: 0.0236 - acc: 0.9928\n",
      "4074/4074 [==============================] - 1s 341us/step\n",
      "8149/8149 [==============================] - 1s 173us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 5s 581us/step - loss: 0.1080 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 364us/step - loss: 0.0472 - acc: 0.9855\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 357us/step - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 357us/step - loss: 0.0356 - acc: 0.9888\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 376us/step - loss: 0.0327 - acc: 0.9904\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 375us/step - loss: 0.0292 - acc: 0.9919\n",
      "4074/4074 [==============================] - 1s 332us/step\n",
      "8149/8149 [==============================] - 1s 168us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 6s 506us/step - loss: 0.0829 - acc: 0.9748\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 4s 360us/step - loss: 0.0404 - acc: 0.9883\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 4s 354us/step - loss: 0.0340 - acc: 0.9885\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 4s 348us/step - loss: 0.0293 - acc: 0.9912\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 4s 353us/step - loss: 0.0256 - acc: 0.9923\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 4s 350us/step - loss: 0.0223 - acc: 0.9935\n",
      "Best: 0.989282 using {'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.988464 (0.000696) with: {'batch_size': 10, 'epochs': 6, 'loss': 'categorical_crossentropy', 'optimizer': 'SGD'}\n",
      "0.989282 (0.001335) with: {'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "Best: 0.989282 using {'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "2060/2060 [==============================] - 1s 560us/step\n",
      "Test Accuracy 0.98543689088914\n"
     ]
    }
   ],
   "source": [
    "##### LOSS FUNCTION #####\n",
    "\n",
    "def create_model(optimizer, loss):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution        \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {\n",
    "              'epochs': [6],\n",
    "              'batch_size': [10],\n",
    "              'optimizer': ['SGD'],\n",
    "              'loss': ['categorical_crossentropy', 'binary_crossentropy']\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 7s 853us/step - loss: 0.6896 - acc: 0.5647\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 397us/step - loss: 0.6829 - acc: 0.6183\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 3s 399us/step - loss: 0.4644 - acc: 0.9001\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 448us/step - loss: 0.1580 - acc: 0.9572\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 444us/step - loss: 0.1045 - acc: 0.9676\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 3s 418us/step - loss: 0.0875 - acc: 0.9709\n",
      "4075/4075 [==============================] - 2s 596us/step\n",
      "8148/8148 [==============================] - 2s 226us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 7s 829us/step - loss: 0.6903 - acc: 0.5291\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 375us/step - loss: 0.6854 - acc: 0.5559\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 374us/step - loss: 0.6666 - acc: 0.7033\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 377us/step - loss: 0.3045 - acc: 0.9400\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 374us/step - loss: 0.0935 - acc: 0.9709\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 386us/step - loss: 0.0631 - acc: 0.9804\n",
      "4074/4074 [==============================] - 2s 591us/step\n",
      "8149/8149 [==============================] - 2s 201us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 7s 861us/step - loss: 0.6877 - acc: 0.5960\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 420us/step - loss: 0.6779 - acc: 0.6553\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 428us/step - loss: 0.4883 - acc: 0.9086\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 431us/step - loss: 0.1621 - acc: 0.9563\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 430us/step - loss: 0.1000 - acc: 0.9675\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 424us/step - loss: 0.0754 - acc: 0.9763\n",
      "4074/4074 [==============================] - 2s 601us/step\n",
      "8149/8149 [==============================] - 2s 213us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 7s 901us/step - loss: 0.1052 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 428us/step - loss: 0.0502 - acc: 0.9833\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 431us/step - loss: 0.0408 - acc: 0.9869\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 430us/step - loss: 0.0351 - acc: 0.9890\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 444us/step - loss: 0.0315 - acc: 0.9909\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 430us/step - loss: 0.0281 - acc: 0.9917\n",
      "4075/4075 [==============================] - 2s 609us/step\n",
      "8148/8148 [==============================] - 2s 217us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 7s 899us/step - loss: 0.1074 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 441us/step - loss: 0.0443 - acc: 0.9860\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 439us/step - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 436us/step - loss: 0.0304 - acc: 0.9897\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 437us/step - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 433us/step - loss: 0.0236 - acc: 0.9928\n",
      "4074/4074 [==============================] - 2s 610us/step\n",
      "8149/8149 [==============================] - 2s 217us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 973us/step - loss: 0.1080 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 437us/step - loss: 0.0472 - acc: 0.9855\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 438us/step - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 439us/step - loss: 0.0356 - acc: 0.9888\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 441us/step - loss: 0.0327 - acc: 0.9904\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 444us/step - loss: 0.0292 - acc: 0.9920\n",
      "4074/4074 [==============================] - 5s 1ms/step\n",
      "8149/8149 [==============================] - 2s 214us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 13s 2ms/step - loss: 0.0899 - acc: 0.9731\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 438us/step - loss: 0.0464 - acc: 0.9854\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 441us/step - loss: 0.0394 - acc: 0.9890\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 446us/step - loss: 0.0357 - acc: 0.9891\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 444us/step - loss: 0.0327 - acc: 0.9904\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 445us/step - loss: 0.0298 - acc: 0.9914\n",
      "4075/4075 [==============================] - 3s 660us/step\n",
      "8148/8148 [==============================] - 2s 227us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 945us/step - loss: 0.1007 - acc: 0.9712\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 443us/step - loss: 0.0455 - acc: 0.9859\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 448us/step - loss: 0.0362 - acc: 0.9880\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 468us/step - loss: 0.0312 - acc: 0.9907\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 465us/step - loss: 0.0279 - acc: 0.9914\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 461us/step - loss: 0.0253 - acc: 0.9912\n",
      "4074/4074 [==============================] - 3s 661us/step\n",
      "8149/8149 [==============================] - 2s 241us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 1ms/step - loss: 0.1053 - acc: 0.9714\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 465us/step - loss: 0.0506 - acc: 0.9845\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 468us/step - loss: 0.0432 - acc: 0.9869\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 468us/step - loss: 0.0389 - acc: 0.9877\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 472us/step - loss: 0.0353 - acc: 0.9887\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 476us/step - loss: 0.0327 - acc: 0.9899\n",
      "4074/4074 [==============================] - 3s 777us/step\n",
      "8149/8149 [==============================] - 2s 242us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 0.1921 - acc: 0.9486\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 477us/step - loss: 0.0719 - acc: 0.9759\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 477us/step - loss: 0.0596 - acc: 0.9783\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 482us/step - loss: 0.0531 - acc: 0.9822\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 475us/step - loss: 0.0491 - acc: 0.9832\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 513us/step - loss: 0.0464 - acc: 0.9843\n",
      "4075/4075 [==============================] - 6s 1ms/step\n",
      "8148/8148 [==============================] - 2s 239us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 13s 2ms/step - loss: 0.2027 - acc: 0.9422\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 481us/step - loss: 0.0721 - acc: 0.9746\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 479us/step - loss: 0.0583 - acc: 0.9804\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 474us/step - loss: 0.0511 - acc: 0.9832\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 472us/step - loss: 0.0459 - acc: 0.9849\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 476us/step - loss: 0.0426 - acc: 0.9865\n",
      "4074/4074 [==============================] - 3s 702us/step\n",
      "8149/8149 [==============================] - 2s 245us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 1ms/step - loss: 0.1994 - acc: 0.9529\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 474us/step - loss: 0.0720 - acc: 0.9762\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 485us/step - loss: 0.0591 - acc: 0.9812\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 420us/step - loss: 0.0532 - acc: 0.9836\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 418us/step - loss: 0.0495 - acc: 0.9834\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 415us/step - loss: 0.0467 - acc: 0.9867\n",
      "4074/4074 [==============================] - 3s 721us/step\n",
      "8149/8149 [==============================] - 2s 253us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 10s 783us/step - loss: 0.0950 - acc: 0.9701\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 5s 415us/step - loss: 0.0419 - acc: 0.9866\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 5s 416us/step - loss: 0.0347 - acc: 0.9885\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 5s 414us/step - loss: 0.0297 - acc: 0.9905\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 5s 416us/step - loss: 0.0260 - acc: 0.9925\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 5s 418us/step - loss: 0.0226 - acc: 0.9933\n",
      "Best: 0.989282 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.977747 (0.002806) with: {'activation_1': 'softmax', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.989282 (0.001335) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.987646 (0.000614) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.983965 (0.000810) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "Best: 0.989282 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "2060/2060 [==============================] - 2s 1ms/step\n",
      "Test Accuracy 0.9883495129427864\n"
     ]
    }
   ],
   "source": [
    "##### NEURON ACTIVATION FUNCTION 1 #####\n",
    "\n",
    "def create_model(optimizer, loss, activation_1, activation_2, activation_3):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation=activation_1)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation=activation_2)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation=activation_3))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [6],\n",
    "              'batch_size': [10],\n",
    "              'optimizer': ['SGD'],\n",
    "              'loss': ['binary_crossentropy'],\n",
    "              'activation_1': ['softmax', 'relu', 'tanh', 'sigmoid'],\n",
    "              'activation_2': ['relu'],\n",
    "              'activation_3': ['softmax']\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 0.6930 - acc: 0.5147\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 419us/step - loss: 0.6907 - acc: 0.5459\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 438us/step - loss: 0.6877 - acc: 0.5611\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 437us/step - loss: 0.6822 - acc: 0.6632\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 435us/step - loss: 0.6022 - acc: 0.9014\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 3s 419us/step - loss: 0.2606 - acc: 0.9621\n",
      "4075/4075 [==============================] - 3s 744us/step\n",
      "8148/8148 [==============================] - 2s 271us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 989us/step - loss: 0.6919 - acc: 0.5192\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 419us/step - loss: 0.6896 - acc: 0.5180\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 414us/step - loss: 0.6869 - acc: 0.5177\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 418us/step - loss: 0.6819 - acc: 0.5396\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 421us/step - loss: 0.6577 - acc: 0.6786\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 423us/step - loss: 0.4062 - acc: 0.9529\n",
      "4074/4074 [==============================] - 3s 767us/step\n",
      "8149/8149 [==============================] - 2s 264us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 1ms/step - loss: 0.6908 - acc: 0.5237\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 426us/step - loss: 0.6860 - acc: 0.5693\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 424us/step - loss: 0.6483 - acc: 0.8543\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 422us/step - loss: 0.3922 - acc: 0.9528\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 423us/step - loss: 0.2245 - acc: 0.9708\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 420us/step - loss: 0.1304 - acc: 0.9786\n",
      "4074/4074 [==============================] - 3s 762us/step\n",
      "8149/8149 [==============================] - 2s 261us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 0.1052 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 451us/step - loss: 0.0502 - acc: 0.9834\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 446us/step - loss: 0.0407 - acc: 0.9870\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 452us/step - loss: 0.0351 - acc: 0.9890\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 463us/step - loss: 0.0314 - acc: 0.9909\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 459us/step - loss: 0.0280 - acc: 0.9918\n",
      "4075/4075 [==============================] - 3s 744us/step\n",
      "8148/8148 [==============================] - 2s 245us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.1074 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 465us/step - loss: 0.0443 - acc: 0.9860\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 464us/step - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 472us/step - loss: 0.0304 - acc: 0.9897\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 471us/step - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 467us/step - loss: 0.0236 - acc: 0.9928\n",
      "4074/4074 [==============================] - 6s 1ms/step\n",
      "8149/8149 [==============================] - 2s 241us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 16s 2ms/step - loss: 0.1080 - acc: 0.9687\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 468us/step - loss: 0.0472 - acc: 0.9855\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 434us/step - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 415us/step - loss: 0.0356 - acc: 0.9888\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 422us/step - loss: 0.0327 - acc: 0.9904\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 381us/step - loss: 0.0292 - acc: 0.9919\n",
      "4074/4074 [==============================] - 3s 827us/step\n",
      "8149/8149 [==============================] - 2s 289us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 8s 983us/step - loss: 0.0873 - acc: 0.9747\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 375us/step - loss: 0.0438 - acc: 0.9861\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 3s 378us/step - loss: 0.0361 - acc: 0.9894\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 3s 377us/step - loss: 0.0318 - acc: 0.9903\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 3s 384us/step - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 3s 379us/step - loss: 0.0248 - acc: 0.9929\n",
      "4075/4075 [==============================] - 3s 814us/step\n",
      "8148/8148 [==============================] - 2s 289us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 999us/step - loss: 0.0955 - acc: 0.9714\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 378us/step - loss: 0.0434 - acc: 0.9874\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 378us/step - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 380us/step - loss: 0.0283 - acc: 0.9914\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 383us/step - loss: 0.0243 - acc: 0.9928\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 381us/step - loss: 0.0212 - acc: 0.9928\n",
      "4074/4074 [==============================] - 3s 820us/step\n",
      "8149/8149 [==============================] - 2s 294us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 8s 1ms/step - loss: 0.1025 - acc: 0.9696\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 3s 379us/step - loss: 0.0497 - acc: 0.9845\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 380us/step - loss: 0.0415 - acc: 0.9872\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 383us/step - loss: 0.0364 - acc: 0.9890\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 379us/step - loss: 0.0320 - acc: 0.9901\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 382us/step - loss: 0.0286 - acc: 0.9919\n",
      "4074/4074 [==============================] - 3s 839us/step\n",
      "8149/8149 [==============================] - 2s 295us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 8s 1ms/step - loss: 0.2136 - acc: 0.9453\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 413us/step - loss: 0.0707 - acc: 0.9777\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 3s 415us/step - loss: 0.0573 - acc: 0.9812\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 3s 405us/step - loss: 0.0508 - acc: 0.9840\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 3s 413us/step - loss: 0.0464 - acc: 0.9849\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 441us/step - loss: 0.0438 - acc: 0.9859\n",
      "4075/4075 [==============================] - 4s 896us/step\n",
      "8148/8148 [==============================] - 2s 299us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.2248 - acc: 0.9415\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 486us/step - loss: 0.0697 - acc: 0.9775\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 467us/step - loss: 0.0551 - acc: 0.9810\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 444us/step - loss: 0.0476 - acc: 0.9853\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 442us/step - loss: 0.0426 - acc: 0.9860\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 452us/step - loss: 0.0392 - acc: 0.9871\n",
      "4074/4074 [==============================] - 3s 826us/step\n",
      "8149/8149 [==============================] - 2s 268us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.2124 - acc: 0.9477\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 467us/step - loss: 0.0700 - acc: 0.9791\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 467us/step - loss: 0.0565 - acc: 0.9832\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 459us/step - loss: 0.0501 - acc: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 436us/step - loss: 0.0466 - acc: 0.9853\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 443us/step - loss: 0.0438 - acc: 0.9865\n",
      "4074/4074 [==============================] - 4s 884us/step\n",
      "8149/8149 [==============================] - 2s 288us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 13s 1ms/step - loss: 0.0950 - acc: 0.9701\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 6s 511us/step - loss: 0.0419 - acc: 0.9866\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 5s 448us/step - loss: 0.0347 - acc: 0.9885\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 5s 446us/step - loss: 0.0297 - acc: 0.9905\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 5s 446us/step - loss: 0.0261 - acc: 0.9925\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 5s 449us/step - loss: 0.0226 - acc: 0.9931\n",
      "Best: 0.989364 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.972347 (0.008485) with: {'activation_1': 'relu', 'activation_2': 'softmax', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.989364 (0.001423) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.988710 (0.000401) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.984701 (0.001206) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "Best: 0.989364 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "2060/2060 [==============================] - 3s 1ms/step\n",
      "Test Accuracy 0.9878640759338453\n"
     ]
    }
   ],
   "source": [
    "##### NEURON ACTIVATION FUNCTION 2 #####\n",
    "\n",
    "def create_model(optimizer, loss, activation_1, activation_2, activation_3):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation=activation_1)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation=activation_2)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation=activation_3))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [6],\n",
    "              'batch_size': [10],\n",
    "              'optimizer': ['SGD'],\n",
    "              'loss': ['binary_crossentropy'],\n",
    "              'activation_1': ['relu'],\n",
    "              'activation_2': ['softmax', 'relu', 'tanh', 'sigmoid'],\n",
    "              'activation_3': ['softmax']\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 0.1111 - acc: 0.9674\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 452us/step - loss: 0.0479 - acc: 0.9851\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 470us/step - loss: 0.0393 - acc: 0.9881\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 489us/step - loss: 0.0339 - acc: 0.9907\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 466us/step - loss: 0.0299 - acc: 0.9913\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 445us/step - loss: 0.0270 - acc: 0.9921\n",
      "4075/4075 [==============================] - 4s 879us/step\n",
      "8148/8148 [==============================] - 2s 284us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.1087 - acc: 0.9694\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 449us/step - loss: 0.0460 - acc: 0.9848\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 444us/step - loss: 0.0369 - acc: 0.9881\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 449us/step - loss: 0.0317 - acc: 0.9902\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 452us/step - loss: 0.0275 - acc: 0.9914\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 447us/step - loss: 0.0245 - acc: 0.9923\n",
      "4074/4074 [==============================] - 4s 880us/step\n",
      "8149/8149 [==============================] - 2s 276us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.1004 - acc: 0.9710\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 431us/step - loss: 0.0500 - acc: 0.9844\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 3s 427us/step - loss: 0.0418 - acc: 0.9874\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 427us/step - loss: 0.0366 - acc: 0.9886\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 428us/step - loss: 0.0333 - acc: 0.9894\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 431us/step - loss: 0.0286 - acc: 0.9910\n",
      "4074/4074 [==============================] - 4s 860us/step\n",
      "8149/8149 [==============================] - 2s 236us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 4.1691 - acc: 0.5903\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 3s 429us/step - loss: 4.1273 - acc: 0.5495\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 3s 426us/step - loss: 4.1215 - acc: 0.5378\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 449us/step - loss: 4.1190 - acc: 0.5324\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 470us/step - loss: 4.1167 - acc: 0.5319\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 477us/step - loss: 2.8050 - acc: 0.5624\n",
      "4075/4075 [==============================] - 4s 867us/step\n",
      "8148/8148 [==============================] - 2s 265us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 10s 1ms/step - loss: 2.5315 - acc: 0.6158\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 484us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 482us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 483us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 483us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 487us/step - loss: 8.0590 - acc: 0.5000\n",
      "4074/4074 [==============================] - 4s 889us/step\n",
      "8149/8149 [==============================] - 2s 269us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 10s 1ms/step - loss: 7.9543 - acc: 0.0019\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 481us/step - loss: 7.9712 - acc: 0.0000e+00\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 491us/step - loss: 7.9712 - acc: 0.0000e+00\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 487us/step - loss: 7.9712 - acc: 0.0000e+00\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 477us/step - loss: 7.9712 - acc: 0.0000e+00\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 479us/step - loss: 7.9712 - acc: 0.0000e+00\n",
      "4074/4074 [==============================] - 4s 887us/step\n",
      "8149/8149 [==============================] - 2s 260us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 10s 1ms/step - loss: 1.0571 - acc: 0.6195\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 503us/step - loss: 0.1143 - acc: 0.5737\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 494us/step - loss: 0.0650 - acc: 0.5566\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 493us/step - loss: 0.0514 - acc: 0.5391\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 499us/step - loss: 0.0424 - acc: 0.5335\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 498us/step - loss: 0.0372 - acc: 0.5281\n",
      "4075/4075 [==============================] - 4s 934us/step\n",
      "8148/8148 [==============================] - 3s 314us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 11s 1ms/step - loss: 0.5047 - acc: 0.6450\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 498us/step - loss: 8.2994 - acc: 0.2411\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 489us/step - loss: 8.2994 - acc: 0.2411\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 3s 386us/step - loss: 8.2994 - acc: 0.2411\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 3s 396us/step - loss: 8.2994 - acc: 0.2411\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 3s 428us/step - loss: 8.2994 - acc: 0.2411\n",
      "4074/4074 [==============================] - 4s 1ms/step\n",
      "8149/8149 [==============================] - 2s 282us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 10s 1ms/step - loss: 0.1517 - acc: 0.7041\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 453us/step - loss: 0.0717 - acc: 0.5722\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 474us/step - loss: 0.0846 - acc: 0.5607\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 462us/step - loss: 0.0549 - acc: 0.5674\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 459us/step - loss: 0.1546 - acc: 0.5377\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 459us/step - loss: 0.0524 - acc: 0.5943\n",
      "4074/4074 [==============================] - 4s 963us/step\n",
      "8149/8149 [==============================] - 2s 295us/step\n",
      "Epoch 1/6\n",
      "8148/8148 [==============================] - 10s 1ms/step - loss: 0.1523 - acc: 0.9563\n",
      "Epoch 2/6\n",
      "8148/8148 [==============================] - 4s 474us/step - loss: 0.0577 - acc: 0.9809\n",
      "Epoch 3/6\n",
      "8148/8148 [==============================] - 4s 474us/step - loss: 0.0483 - acc: 0.9832\n",
      "Epoch 4/6\n",
      "8148/8148 [==============================] - 4s 498us/step - loss: 0.0433 - acc: 0.9867\n",
      "Epoch 5/6\n",
      "8148/8148 [==============================] - 4s 478us/step - loss: 0.0396 - acc: 0.9877\n",
      "Epoch 6/6\n",
      "8148/8148 [==============================] - 4s 498us/step - loss: 0.0368 - acc: 0.9888\n",
      "4075/4075 [==============================] - 4s 980us/step\n",
      "8148/8148 [==============================] - 2s 305us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 11s 1ms/step - loss: 0.1618 - acc: 0.9576\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 483us/step - loss: 0.0563 - acc: 0.9818\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 474us/step - loss: 0.0449 - acc: 0.9856\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 489us/step - loss: 0.0389 - acc: 0.9874\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 495us/step - loss: 0.0345 - acc: 0.9893\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 495us/step - loss: 0.0313 - acc: 0.9894\n",
      "4074/4074 [==============================] - 4s 979us/step\n",
      "8149/8149 [==============================] - 2s 302us/step\n",
      "Epoch 1/6\n",
      "8149/8149 [==============================] - 11s 1ms/step - loss: 0.1650 - acc: 0.9620\n",
      "Epoch 2/6\n",
      "8149/8149 [==============================] - 4s 513us/step - loss: 0.0569 - acc: 0.9831\n",
      "Epoch 3/6\n",
      "8149/8149 [==============================] - 4s 499us/step - loss: 0.0478 - acc: 0.9854\n",
      "Epoch 4/6\n",
      "8149/8149 [==============================] - 4s 484us/step - loss: 0.0428 - acc: 0.9876\n",
      "Epoch 5/6\n",
      "8149/8149 [==============================] - 4s 512us/step - loss: 0.0396 - acc: 0.9881\n",
      "Epoch 6/6\n",
      "8149/8149 [==============================] - 4s 491us/step - loss: 0.0370 - acc: 0.9893\n",
      "4074/4074 [==============================] - 4s 1ms/step\n",
      "8149/8149 [==============================] - 3s 316us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "12223/12223 [==============================] - 12s 988us/step - loss: 0.0950 - acc: 0.9703\n",
      "Epoch 2/6\n",
      "12223/12223 [==============================] - 6s 457us/step - loss: 0.0419 - acc: 0.9866\n",
      "Epoch 3/6\n",
      "12223/12223 [==============================] - 6s 456us/step - loss: 0.0347 - acc: 0.9886\n",
      "Epoch 4/6\n",
      "12223/12223 [==============================] - 6s 467us/step - loss: 0.0297 - acc: 0.9905\n",
      "Epoch 5/6\n",
      "12223/12223 [==============================] - 5s 406us/step - loss: 0.0260 - acc: 0.9924\n",
      "Epoch 6/6\n",
      "12223/12223 [==============================] - 5s 423us/step - loss: 0.0226 - acc: 0.9932\n",
      "Best: 0.988464 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.988464 (0.000696) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.369631 (0.265103) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.438681 (0.134332) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "0.986746 (0.000362) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "Best: 0.988464 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'softmax', 'batch_size': 10, 'epochs': 6, 'loss': 'binary_crossentropy', 'optimizer': 'SGD'}\n",
      "2060/2060 [==============================] - 4s 2ms/step\n",
      "Test Accuracy 0.9883495129427864\n"
     ]
    }
   ],
   "source": [
    "##### NEURON ACTIVATION FUNCTION 3 #####\n",
    "\n",
    "def create_model(optimizer, loss, activation_1, activation_2, activation_3):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation=activation_1)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation=activation_2)) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation=activation_3))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [6],\n",
    "              'batch_size': [10],\n",
    "              'optimizer': ['SGD'],\n",
    "              'loss': ['binary_crossentropy'],\n",
    "              'activation_1': ['relu'],\n",
    "              'activation_2': ['relu'],\n",
    "              'activation_3': ['softmax', 'relu', 'tanh', 'sigmoid']\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Epoch 1/20\n",
      "8148/8148 [==============================] - 9s 1ms/step - loss: 0.1572 - acc: 0.9566\n",
      "Epoch 2/20\n",
      "8148/8148 [==============================] - 2s 247us/step - loss: 0.0610 - acc: 0.9806\n",
      "Epoch 3/20\n",
      "8148/8148 [==============================] - 2s 243us/step - loss: 0.0492 - acc: 0.9842\n",
      "Epoch 4/20\n",
      "8148/8148 [==============================] - 2s 242us/step - loss: 0.0432 - acc: 0.9871\n",
      "Epoch 5/20\n",
      "8148/8148 [==============================] - 2s 246us/step - loss: 0.0391 - acc: 0.9886\n",
      "Epoch 6/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0360 - acc: 0.9892\n",
      "Epoch 7/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0335 - acc: 0.9905\n",
      "Epoch 8/20\n",
      "8148/8148 [==============================] - 2s 242us/step - loss: 0.0310 - acc: 0.9912\n",
      "Epoch 9/20\n",
      "8148/8148 [==============================] - 2s 246us/step - loss: 0.0294 - acc: 0.9908\n",
      "Epoch 10/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0276 - acc: 0.9921\n",
      "Epoch 11/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0260 - acc: 0.9925\n",
      "Epoch 12/20\n",
      "8148/8148 [==============================] - 2s 246us/step - loss: 0.0247 - acc: 0.9926\n",
      "Epoch 13/20\n",
      "8148/8148 [==============================] - 2s 247us/step - loss: 0.0230 - acc: 0.9940\n",
      "Epoch 14/20\n",
      "8148/8148 [==============================] - 2s 249us/step - loss: 0.0220 - acc: 0.9935\n",
      "Epoch 15/20\n",
      "8148/8148 [==============================] - 2s 246us/step - loss: 0.0208 - acc: 0.9944\n",
      "Epoch 16/20\n",
      "8148/8148 [==============================] - 2s 243us/step - loss: 0.0199 - acc: 0.9948\n",
      "Epoch 17/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0187 - acc: 0.9955\n",
      "Epoch 18/20\n",
      "8148/8148 [==============================] - 2s 248us/step - loss: 0.0178 - acc: 0.9956\n",
      "Epoch 19/20\n",
      "8148/8148 [==============================] - 2s 244us/step - loss: 0.0168 - acc: 0.9957\n",
      "Epoch 20/20\n",
      "8148/8148 [==============================] - 2s 251us/step - loss: 0.0158 - acc: 0.9959\n",
      "4075/4075 [==============================] - 4s 896us/step\n",
      "8148/8148 [==============================] - 1s 165us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.1602 - acc: 0.9569\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 2s 246us/step - loss: 0.0600 - acc: 0.9813\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 2s 245us/step - loss: 0.0477 - acc: 0.9852\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 2s 245us/step - loss: 0.0409 - acc: 0.9872\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 2s 244us/step - loss: 0.0369 - acc: 0.9890\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 2s 250us/step - loss: 0.0330 - acc: 0.9902\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0306 - acc: 0.9906\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0262 - acc: 0.9918\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0244 - acc: 0.9926\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 2s 248us/step - loss: 0.0226 - acc: 0.9929\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 2s 246us/step - loss: 0.0216 - acc: 0.9936\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 2s 245us/step - loss: 0.0202 - acc: 0.9941\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 2s 250us/step - loss: 0.0192 - acc: 0.9946\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 2s 246us/step - loss: 0.0176 - acc: 0.9953\n",
      "Epoch 16/20\n",
      "8149/8149 [==============================] - 2s 246us/step - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 2s 249us/step - loss: 0.0158 - acc: 0.9958\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 2s 250us/step - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 2s 248us/step - loss: 0.0140 - acc: 0.9961\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 2s 247us/step - loss: 0.0130 - acc: 0.9964\n",
      "4074/4074 [==============================] - 4s 891us/step\n",
      "8149/8149 [==============================] - 1s 160us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 9s 1ms/step - loss: 0.1601 - acc: 0.9542\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 2s 250us/step - loss: 0.0604 - acc: 0.9799\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 2s 253us/step - loss: 0.0485 - acc: 0.9849\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 2s 251us/step - loss: 0.0428 - acc: 0.9867\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 2s 250us/step - loss: 0.0387 - acc: 0.9890\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 2s 252us/step - loss: 0.0360 - acc: 0.9892\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 2s 252us/step - loss: 0.0332 - acc: 0.9901\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 2s 256us/step - loss: 0.0308 - acc: 0.9907\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 2s 261us/step - loss: 0.0289 - acc: 0.9919\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 2s 259us/step - loss: 0.0268 - acc: 0.9929\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 2s 294us/step - loss: 0.0255 - acc: 0.9936\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 2s 279us/step - loss: 0.0241 - acc: 0.9935\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 2s 289us/step - loss: 0.0225 - acc: 0.9942\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 2s 288us/step - loss: 0.0213 - acc: 0.9950\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 2s 287us/step - loss: 0.0202 - acc: 0.9948\n",
      "Epoch 16/20\n",
      "8149/8149 [==============================] - 2s 289us/step - loss: 0.0191 - acc: 0.9952\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 2s 291us/step - loss: 0.0180 - acc: 0.9957\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 2s 293us/step - loss: 0.0172 - acc: 0.9961\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 2s 285us/step - loss: 0.0163 - acc: 0.9963\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 2s 290us/step - loss: 0.0154 - acc: 0.9966\n",
      "4074/4074 [==============================] - 4s 871us/step\n",
      "8149/8149 [==============================] - 1s 168us/step\n",
      "Epoch 1/20\n",
      "8148/8148 [==============================] - 8s 1ms/step - loss: 0.2126 - acc: 0.9453\n",
      "Epoch 2/20\n",
      "8148/8148 [==============================] - 1s 166us/step - loss: 0.0792 - acc: 0.9741\n",
      "Epoch 3/20\n",
      "8148/8148 [==============================] - 1s 160us/step - loss: 0.0623 - acc: 0.9791\n",
      "Epoch 4/20\n",
      "8148/8148 [==============================] - 1s 161us/step - loss: 0.0542 - acc: 0.9821\n",
      "Epoch 5/20\n",
      "8148/8148 [==============================] - 1s 163us/step - loss: 0.0489 - acc: 0.9838\n",
      "Epoch 6/20\n",
      "8148/8148 [==============================] - 1s 164us/step - loss: 0.0452 - acc: 0.9854\n",
      "Epoch 7/20\n",
      "8148/8148 [==============================] - 1s 165us/step - loss: 0.0424 - acc: 0.9869\n",
      "Epoch 8/20\n",
      "8148/8148 [==============================] - 1s 161us/step - loss: 0.0404 - acc: 0.9867\n",
      "Epoch 9/20\n",
      "8148/8148 [==============================] - 1s 162us/step - loss: 0.0384 - acc: 0.9885\n",
      "Epoch 10/20\n",
      "8148/8148 [==============================] - 1s 161us/step - loss: 0.0369 - acc: 0.9883\n",
      "Epoch 11/20\n",
      "8148/8148 [==============================] - 1s 162us/step - loss: 0.0354 - acc: 0.9897\n",
      "Epoch 12/20\n",
      "8148/8148 [==============================] - 1s 160us/step - loss: 0.0341 - acc: 0.9893\n",
      "Epoch 13/20\n",
      "8148/8148 [==============================] - 1s 158us/step - loss: 0.0331 - acc: 0.9903\n",
      "Epoch 14/20\n",
      "8148/8148 [==============================] - 1s 162us/step - loss: 0.0320 - acc: 0.9903\n",
      "Epoch 15/20\n",
      "8148/8148 [==============================] - 1s 160us/step - loss: 0.0310 - acc: 0.9913\n",
      "Epoch 16/20\n",
      "8148/8148 [==============================] - 1s 164us/step - loss: 0.0299 - acc: 0.9904\n",
      "Epoch 17/20\n",
      "8148/8148 [==============================] - 1s 165us/step - loss: 0.0290 - acc: 0.9915\n",
      "Epoch 18/20\n",
      "8148/8148 [==============================] - 1s 162us/step - loss: 0.0283 - acc: 0.9914\n",
      "Epoch 19/20\n",
      "8148/8148 [==============================] - 1s 155us/step - loss: 0.0270 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "8148/8148 [==============================] - 1s 153us/step - loss: 0.0267 - acc: 0.9920\n",
      "4075/4075 [==============================] - 4s 902us/step\n",
      "8148/8148 [==============================] - 1s 94us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 8s 1ms/step - loss: 0.2528 - acc: 0.9264\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 1s 139us/step - loss: 0.0840 - acc: 0.9737\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0653 - acc: 0.9788\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 1s 142us/step - loss: 0.0560 - acc: 0.9825\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0497 - acc: 0.9833\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 1s 141us/step - loss: 0.0454 - acc: 0.9850\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 1s 141us/step - loss: 0.0420 - acc: 0.9865\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 1s 142us/step - loss: 0.0391 - acc: 0.9877\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0368 - acc: 0.9881\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0349 - acc: 0.9886\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 1s 144us/step - loss: 0.0331 - acc: 0.9893\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 1s 142us/step - loss: 0.0317 - acc: 0.9893\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 1s 141us/step - loss: 0.0301 - acc: 0.9901\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0287 - acc: 0.9907\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 1s 139us/step - loss: 0.0276 - acc: 0.9914\n",
      "Epoch 16/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0266 - acc: 0.9914\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0256 - acc: 0.9924\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 1s 142us/step - loss: 0.0247 - acc: 0.9919\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 1s 144us/step - loss: 0.0238 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 1s 141us/step - loss: 0.0230 - acc: 0.9926\n",
      "4074/4074 [==============================] - 3s 822us/step\n",
      "8149/8149 [==============================] - 1s 88us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 8s 997us/step - loss: 0.1991 - acc: 0.9536\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0739 - acc: 0.9789\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0597 - acc: 0.9825\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0528 - acc: 0.9845\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 1s 137us/step - loss: 0.0482 - acc: 0.9854\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 1s 136us/step - loss: 0.0453 - acc: 0.9860\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 1s 137us/step - loss: 0.0431 - acc: 0.9870\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 1s 142us/step - loss: 0.0410 - acc: 0.9888\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0394 - acc: 0.9890\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 1s 143us/step - loss: 0.0378 - acc: 0.9890\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 1s 140us/step - loss: 0.0366 - acc: 0.9897\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 1s 138us/step - loss: 0.0356 - acc: 0.9896\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 1s 138us/step - loss: 0.0346 - acc: 0.9903\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 1s 138us/step - loss: 0.0336 - acc: 0.9909\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 1s 135us/step - loss: 0.0326 - acc: 0.9907\n",
      "Epoch 16/20\n",
      "8149/8149 [==============================] - 1s 133us/step - loss: 0.0316 - acc: 0.9904\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 1s 135us/step - loss: 0.0308 - acc: 0.9910\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 1s 136us/step - loss: 0.0299 - acc: 0.9921\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 1s 139us/step - loss: 0.0293 - acc: 0.9920\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 1s 137us/step - loss: 0.0283 - acc: 0.9923\n",
      "4074/4074 [==============================] - 3s 811us/step\n",
      "8149/8149 [==============================] - 1s 89us/step\n",
      "Epoch 1/20\n",
      "8148/8148 [==============================] - 8s 944us/step - loss: 0.2961 - acc: 0.9153\n",
      "Epoch 2/20\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.1030 - acc: 0.9714\n",
      "Epoch 3/20\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0780 - acc: 0.9756\n",
      "Epoch 4/20\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0667 - acc: 0.9791\n",
      "Epoch 5/20\n",
      "8148/8148 [==============================] - 1s 97us/step - loss: 0.0599 - acc: 0.9812\n",
      "Epoch 6/20\n",
      "8148/8148 [==============================] - 1s 101us/step - loss: 0.0550 - acc: 0.9827\n",
      "Epoch 7/20\n",
      "8148/8148 [==============================] - 1s 99us/step - loss: 0.0516 - acc: 0.9839\n",
      "Epoch 8/20\n",
      "8148/8148 [==============================] - 1s 98us/step - loss: 0.0488 - acc: 0.9850\n",
      "Epoch 9/20\n",
      "8148/8148 [==============================] - 1s 103us/step - loss: 0.0465 - acc: 0.9856\n",
      "Epoch 10/20\n",
      "8148/8148 [==============================] - 1s 103us/step - loss: 0.0447 - acc: 0.9858\n",
      "Epoch 11/20\n",
      "8148/8148 [==============================] - 1s 107us/step - loss: 0.0429 - acc: 0.9865\n",
      "Epoch 12/20\n",
      "8148/8148 [==============================] - 1s 102us/step - loss: 0.0412 - acc: 0.9872\n",
      "Epoch 13/20\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0401 - acc: 0.9875\n",
      "Epoch 14/20\n",
      "8148/8148 [==============================] - 1s 100us/step - loss: 0.0389 - acc: 0.9876\n",
      "Epoch 15/20\n",
      "8148/8148 [==============================] - 1s 102us/step - loss: 0.0378 - acc: 0.9878\n",
      "Epoch 16/20\n",
      "8148/8148 [==============================] - 1s 99us/step - loss: 0.0370 - acc: 0.9883\n",
      "Epoch 17/20\n",
      "8148/8148 [==============================] - 1s 106us/step - loss: 0.0358 - acc: 0.9885\n",
      "Epoch 18/20\n",
      "8148/8148 [==============================] - 1s 104us/step - loss: 0.0350 - acc: 0.9887\n",
      "Epoch 19/20\n",
      "8148/8148 [==============================] - 1s 102us/step - loss: 0.0341 - acc: 0.9890\n",
      "Epoch 20/20\n",
      "8148/8148 [==============================] - 1s 109us/step - loss: 0.0335 - acc: 0.9896\n",
      "4075/4075 [==============================] - 3s 815us/step\n",
      "8148/8148 [==============================] - 1s 64us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 8s 986us/step - loss: 0.2833 - acc: 0.9228\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.1011 - acc: 0.9707\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.0760 - acc: 0.9762\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0647 - acc: 0.9783\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 1s 100us/step - loss: 0.0576 - acc: 0.9801\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 1s 100us/step - loss: 0.0527 - acc: 0.9823\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 1s 100us/step - loss: 0.0489 - acc: 0.9844\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.0458 - acc: 0.9854\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 1s 103us/step - loss: 0.0434 - acc: 0.9865\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 1s 106us/step - loss: 0.0412 - acc: 0.9869\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 1s 104us/step - loss: 0.0394 - acc: 0.9876\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 1s 104us/step - loss: 0.0375 - acc: 0.9886\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 1s 105us/step - loss: 0.0364 - acc: 0.9890\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 1s 107us/step - loss: 0.0351 - acc: 0.9893\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 1s 106us/step - loss: 0.0338 - acc: 0.9897\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8149/8149 [==============================] - 1s 105us/step - loss: 0.0324 - acc: 0.9903\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 1s 103us/step - loss: 0.0316 - acc: 0.9902\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 1s 102us/step - loss: 0.0308 - acc: 0.9910\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.0299 - acc: 0.9913\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 1s 102us/step - loss: 0.0290 - acc: 0.9913\n",
      "4074/4074 [==============================] - 3s 805us/step\n",
      "8149/8149 [==============================] - 1s 66us/step\n",
      "Epoch 1/20\n",
      "8149/8149 [==============================] - 8s 962us/step - loss: 0.2581 - acc: 0.9326\n",
      "Epoch 2/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0965 - acc: 0.9707\n",
      "Epoch 3/20\n",
      "8149/8149 [==============================] - 1s 97us/step - loss: 0.0746 - acc: 0.9752\n",
      "Epoch 4/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0641 - acc: 0.9790\n",
      "Epoch 5/20\n",
      "8149/8149 [==============================] - 1s 97us/step - loss: 0.0576 - acc: 0.9809\n",
      "Epoch 6/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0532 - acc: 0.9825\n",
      "Epoch 7/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0497 - acc: 0.9842\n",
      "Epoch 8/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0472 - acc: 0.9854\n",
      "Epoch 9/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0450 - acc: 0.9860\n",
      "Epoch 10/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0434 - acc: 0.9867\n",
      "Epoch 11/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0417 - acc: 0.9872\n",
      "Epoch 12/20\n",
      "8149/8149 [==============================] - 1s 101us/step - loss: 0.0405 - acc: 0.9876\n",
      "Epoch 13/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0393 - acc: 0.9886\n",
      "Epoch 14/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0382 - acc: 0.9892\n",
      "Epoch 15/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0371 - acc: 0.9892\n",
      "Epoch 16/20\n",
      "8149/8149 [==============================] - 1s 99us/step - loss: 0.0362 - acc: 0.9888\n",
      "Epoch 17/20\n",
      "8149/8149 [==============================] - 1s 98us/step - loss: 0.0355 - acc: 0.9896\n",
      "Epoch 18/20\n",
      "8149/8149 [==============================] - 1s 100us/step - loss: 0.0347 - acc: 0.9897\n",
      "Epoch 19/20\n",
      "8149/8149 [==============================] - 1s 105us/step - loss: 0.0339 - acc: 0.9897\n",
      "Epoch 20/20\n",
      "8149/8149 [==============================] - 1s 105us/step - loss: 0.0332 - acc: 0.9896\n",
      "4074/4074 [==============================] - 3s 801us/step\n",
      "8149/8149 [==============================] - 1s 67us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12223/12223 [==============================] - 10s 838us/step - loss: 0.1296 - acc: 0.9651\n",
      "Epoch 2/20\n",
      "12223/12223 [==============================] - 3s 250us/step - loss: 0.0524 - acc: 0.9837\n",
      "Epoch 3/20\n",
      "12223/12223 [==============================] - 3s 249us/step - loss: 0.0432 - acc: 0.9872\n",
      "Epoch 4/20\n",
      "12223/12223 [==============================] - 3s 248us/step - loss: 0.0385 - acc: 0.9884\n",
      "Epoch 5/20\n",
      "12223/12223 [==============================] - 3s 247us/step - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 6/20\n",
      "12223/12223 [==============================] - 3s 251us/step - loss: 0.0322 - acc: 0.9899\n",
      "Epoch 7/20\n",
      "12223/12223 [==============================] - 3s 248us/step - loss: 0.0297 - acc: 0.9903\n",
      "Epoch 8/20\n",
      "12223/12223 [==============================] - 3s 248us/step - loss: 0.0279 - acc: 0.9912\n",
      "Epoch 9/20\n",
      "12223/12223 [==============================] - 3s 250us/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "12223/12223 [==============================] - 3s 253us/step - loss: 0.0246 - acc: 0.9927\n",
      "Epoch 11/20\n",
      "12223/12223 [==============================] - 3s 247us/step - loss: 0.0227 - acc: 0.9935\n",
      "Epoch 12/20\n",
      "12223/12223 [==============================] - 3s 250us/step - loss: 0.0211 - acc: 0.9940\n",
      "Epoch 13/20\n",
      "12223/12223 [==============================] - 3s 255us/step - loss: 0.0200 - acc: 0.9941\n",
      "Epoch 14/20\n",
      "12223/12223 [==============================] - 3s 263us/step - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 15/20\n",
      "12223/12223 [==============================] - 3s 262us/step - loss: 0.0175 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "12223/12223 [==============================] - 3s 264us/step - loss: 0.0164 - acc: 0.9957\n",
      "Epoch 17/20\n",
      "12223/12223 [==============================] - 3s 268us/step - loss: 0.0154 - acc: 0.9961\n",
      "Epoch 18/20\n",
      "12223/12223 [==============================] - 3s 261us/step - loss: 0.0143 - acc: 0.9966\n",
      "Epoch 19/20\n",
      "12223/12223 [==============================] - 3s 262us/step - loss: 0.0134 - acc: 0.9967\n",
      "Epoch 20/20\n",
      "12223/12223 [==============================] - 3s 261us/step - loss: 0.0127 - acc: 0.9973\n",
      "0.989282 (0.001140) with: {'batch_size': 20, 'epochs': 20}\n",
      "0.988792 (0.001273) with: {'batch_size': 40, 'epochs': 20}\n",
      "0.987564 (0.001224) with: {'batch_size': 60, 'epochs': 20}\n",
      "Best: 0.989282 using {'batch_size': 20, 'epochs': 20}\n",
      "2060/2060 [==============================] - 4s 2ms/step\n",
      " Test Accuracy 0.9898058233909237\n"
     ]
    }
   ],
   "source": [
    "##### Final Model #####\n",
    "##### Epochs - The more the better usually. #####\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # a basic feed-forward model\n",
    "    model.add(Flatten()) \n",
    "    # takes our 28x28 and makes it 1x784\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # a simple fully-connected layer, 128 units, relu activation\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    # our output layer. 2 units for 2 classes. Softmax for probability distribution\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, \n",
    "                  optimizer=keras.optimizers.SGD(), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Test all combinations of the following parameters:\n",
    "param_grid = {'epochs': [20],\n",
    "              'batch_size': [20, 40, 60]\n",
    "              }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=3, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\" Test Accuracy\", grid_result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
